{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "\n",
    "This notebook demonstrates an auto-classification algorithm using the horey old chessnut of distinguishing email ham from spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import nltk\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails = glob.glob('data/emails/*/*')\n",
    "data = {'text': [], 'class': []}\n",
    "for email in emails:\n",
    "    with open(email, 'r', encoding=\"latin-1\") as content:\n",
    "        data['text'].append(content.read())\n",
    "        data['class'].append(email.split('.')[-2])\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: christmas tree farm pictures\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: vastar resources , inc .\\ngary , prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- calpi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : issue\\nfyi - see note below - al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: meter 7268 nov allocation\\nfyi .\\n- -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham            Subject: christmas tree farm pictures\\n\n",
       "1   ham  Subject: vastar resources , inc .\\ngary , prod...\n",
       "2   ham  Subject: calpine daily gas nomination\\n- calpi...\n",
       "3   ham  Subject: re : issue\\nfyi - see note below - al...\n",
       "4   ham  Subject: meter 7268 nov allocation\\nfyi .\\n- -..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function to be used for tokenization\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def tokenize(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        # include only those that contains letters\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            # exclude stop words, those shorter than 3 characters, and those that\n",
    "            # start with non-alphanumeric characters\n",
    "            if token not in stopwords and len(token) > 2 and token[0].isalnum():\n",
    "                filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aabda</th>\n",
       "      <th>aabvmmq</th>\n",
       "      <th>aac</th>\n",
       "      <th>aachecar</th>\n",
       "      <th>aaer</th>\n",
       "      <th>aafco</th>\n",
       "      <th>aaiabe</th>\n",
       "      <th>aaigrcrb</th>\n",
       "      <th>...</th>\n",
       "      <th>zynve</th>\n",
       "      <th>zyqtaqlt</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zyyqywp</th>\n",
       "      <th>zzezrjok</th>\n",
       "      <th>zzn</th>\n",
       "      <th>zzo</th>\n",
       "      <th>zzocb</th>\n",
       "      <th>zzso</th>\n",
       "      <th>zzsyt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45040 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  aaas  aabda  aabvmmq  aac  aachecar  aaer  aafco  aaiabe  aaigrcrb  \\\n",
       "0    0     0      0        0    0         0     0      0       0         0   \n",
       "1    0     0      0        0    0         0     0      0       0         0   \n",
       "2    0     0      0        0    0         0     0      0       0         0   \n",
       "3    0     0      0        0    0         0     0      0       0         0   \n",
       "4    0     0      0        0    0         0     0      0       0         0   \n",
       "\n",
       "   ...    zynve  zyqtaqlt  zyrtec  zyyqywp  zzezrjok  zzn  zzo  zzocb  zzso  \\\n",
       "0  ...        0         0       0        0         0    0    0      0     0   \n",
       "1  ...        0         0       0        0         0    0    0      0     0   \n",
       "2  ...        0         0       0        0         0    0    0      0     0   \n",
       "3  ...        0         0       0        0         0    0    0      0     0   \n",
       "4  ...        0         0       0        0         0    0    0      0     0   \n",
       "\n",
       "   zzsyt  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 45040 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features from all emails -- both ham and spam\n",
    "count_vectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "counts = count_vectorizer.fit_transform(df['text'].values)\n",
    "terms = count_vectorizer.get_feature_names()\n",
    "\n",
    "# build a dataframe of the feature matrix and display a few rows\n",
    "features_df = pd.DataFrame(counts.toarray(), columns=terms)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier\n",
    "classifier = MultinomialNB()\n",
    "targets = df['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free Viagra call today!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am going to a concert tonight in Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>I have a bank account in Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Are you looking for singles?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>How are you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey! It's me Darren. Do you remember me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>We are a design company specializing in web de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification                                               text\n",
       "0           spam                            Free Viagra call today!\n",
       "1            ham       I am going to a concert tonight in Manhattan\n",
       "2           spam                   I have a bank account in Nigeria\n",
       "3           spam                       Are you looking for singles?\n",
       "4            ham                                 How are you doing?\n",
       "5            ham           Hey! It's me Darren. Do you remember me?\n",
       "6           spam  We are a design company specializing in web de..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the classifier\n",
    "examples = [\n",
    "    'Free Viagra call today!', \n",
    "    'I am going to a concert tonight in Manhattan',\n",
    "    'I have a bank account in Nigeria',\n",
    "    'Are you looking for singles?',\n",
    "    'How are you doing?',\n",
    "    \"Hey! It's me Darren. Do you remember me?\",\n",
    "    'We are a design company specializing in web development'\n",
    "]\n",
    "example_counts = count_vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "list(predictions)\n",
    "\n",
    "# make a dataframe of the examples with their corresponding classifications\n",
    "predictions_df = pd.DataFrame([{'text': x, 'classification': y} for x,y in zip(examples, predictions)])\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use scikit piplining to define the feature extraction and training\n",
    "# into a single pipeline. This makes cross-validation code more consice.\n",
    "\n",
    "# The pipeline also makes it easier to experiment with different classifiers.\n",
    "# In the process of iterating over different classifiers and obtaining cross-\n",
    "# validation metrics, we can select the model that best fits the data.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer(tokenizer=tokenize)),\n",
    "    ('classifier',  MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cross-validation procedure\n",
    "\n",
    "def cross_validate():\n",
    "    kf = KFold(n_splits=3)\n",
    "    scores = []\n",
    "    confusion = numpy.array([[0, 0], [0, 0]])\n",
    "\n",
    "    for train_indices, test_indices in kf.split(df):\n",
    "        train_text = df.iloc[train_indices]['text'].values\n",
    "        train_y = df.iloc[train_indices]['class'].values\n",
    "\n",
    "        test_text = df.iloc[test_indices]['text'].values\n",
    "        test_y = df.iloc[test_indices]['class'].values\n",
    "\n",
    "        pipeline.fit(train_text, train_y)\n",
    "        predictions = pipeline.predict(test_text)\n",
    "\n",
    "        confusion += confusion_matrix(test_y, predictions)\n",
    "        score = f1_score(test_y, predictions, pos_label='ham')\n",
    "        scores.append(score)\n",
    "\n",
    "    print('Total emails classified:', len(df))\n",
    "    print('Score:', sum(scores)/len(scores))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion)\n",
    "    \n",
    "#cross_validate() # Uncomment this if you want to run the cross validation step, it's time consuming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
